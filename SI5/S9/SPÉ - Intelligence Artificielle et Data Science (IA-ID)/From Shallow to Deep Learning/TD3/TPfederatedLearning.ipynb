{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP introduction to Federated Learning\n",
    "Diane Lingrand (diane.lingrand@univ-cotedazur.fr)\n",
    "\n",
    "Polytech SI5 / M2 - Advanced Deep Learning - 2022-23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will consider a very simple dataset: MNIST and will simulate a centralised federated learning using a server and few workers. The original MNIST dataset will be split in different subsets with the same number of data for each worker and the same distribution of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:33:26.628618Z",
     "start_time": "2023-01-12T10:33:10.653197Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow.keras.utils\n",
    "import pandas\n",
    "from pandas import DataFrame\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:33:27.010431Z",
     "start_time": "2023-01-12T10:33:26.634854Z"
    }
   },
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:33:27.022640Z",
     "start_time": "2023-01-12T10:33:27.019376Z"
    }
   },
   "outputs": [],
   "source": [
    "nbClasses=10\n",
    "print(\"shape of x_train:\", x_train.shape)\n",
    "print(\"shape of y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-14T19:04:57.361025Z",
     "start_time": "2023-01-14T19:04:55.826500Z"
    }
   },
   "outputs": [],
   "source": [
    "# display a random image from the train dataset (re-run the cell in order to change the image)\n",
    "import matplotlib.pyplot as plt\n",
    "i = random.randint(0,len(x_train)-1)\n",
    "plt.imshow(x_train[i],aspect=\"auto\",cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:37:12.156676Z",
     "start_time": "2023-01-12T10:37:11.950271Z"
    }
   },
   "outputs": [],
   "source": [
    "# flatten the images...\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "# ... and normalize the data (grey levels are integers from 0 to 255)\n",
    "xTrain = x_train.astype('float32')/255\n",
    "xTest = x_test.astype('float32')/255\n",
    "\n",
    "# original labels corresponds to digits. We transform the labels to categorical labels.\n",
    "yTrain = tensorflow.keras.utils.to_categorical(y_train, nbClasses)\n",
    "yTest = tensorflow.keras.utils.to_categorical(y_test, nbClasses)\n",
    "\n",
    "print('shape of xTrain :', xTrain.shape)\n",
    "print('shape of yTrain :', yTrain.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is not exactly about federated learning but allows you to build a benchmark. \n",
    "In this section you will choose a neural network topology, learn its weights using the training set and evaluate it using the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-08T18:11:38.001789Z",
     "start_time": "2023-01-08T18:11:37.933540Z"
    }
   },
   "outputs": [],
   "source": [
    "# NEURAL NETWORKS TOPOLOGY PROPOSITIONS\n",
    "\n",
    "def buildModel1():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(nbClasses, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def buildModel2():\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(100, input_dim=784, activation='relu'))\n",
    "    model.add(Dense(75, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Dense(nbClasses, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def buildModel3():\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(50, input_dim=784, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Dense(nbClasses, activation='softmax'))\n",
    "    return model\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the method \"summary()\", compare the number of weights to be learn for these architectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = buildModel1()\n",
    "m1.summary()\n",
    "#to be continued ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, choose a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel1() # put you choice here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:45:41.562485Z",
     "start_time": "2023-01-12T10:45:41.552477Z"
    }
   },
   "outputs": [],
   "source": [
    "#we need to define the loss function for the training, the optimisation method (RMSprop) and the accuracy as a metric\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:45:42.367826Z",
     "start_time": "2023-01-12T10:45:42.364250Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'val'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:46:53.383247Z",
     "start_time": "2023-01-12T10:45:48.752174Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# we define a callback function that will control if the accuracy \n",
    "# on the validation set (a part of train set) is not changing more than 10-4 with a patience of 20 iterations\n",
    "# If the last accuracy value is not the best one, we still keep the last results\n",
    "# In this example, we extracted 20% of the train set for the validation set that will be used to monitor the convergence.\n",
    "\n",
    "ourCallback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "# let's learn the network again !\n",
    "# We do not know when the training will stop but no more than 2000 epochs.\n",
    "h = model.fit(xTrain, yTrain, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[ourCallback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T10:27:17.243339Z",
     "start_time": "2023-01-06T10:27:17.066796Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_history(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T10:27:47.510996Z",
     "start_time": "2023-01-06T10:27:47.207133Z"
    }
   },
   "outputs": [],
   "source": [
    "pandas.DataFrame(h.history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the value of the F1 score (both train set and test set)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-12T10:47:01.156704Z",
     "start_time": "2023-01-12T10:47:00.183077Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print metrics\n",
    "score = model.evaluate(xTest,yTest)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "pred_test = np.argmax(model.predict(xTest),axis=1)\n",
    "print(pred_test.shape, yTest.shape)\n",
    "print(\"F1 score: \", f1_score(pred_test,np.argmax(yTest,axis=1),average=None))\n",
    "print(\"F1 score micro: \", f1_score(pred_test,np.argmax(yTest,axis=1), average='micro'))\n",
    "print(\"F1 score macro: \", f1_score(pred_test,np.argmax(yTest,axis=1), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T11:23:27.568224Z",
     "start_time": "2023-01-06T11:23:27.099110Z"
    }
   },
   "outputs": [],
   "source": [
    "# display the confusion matrix:\n",
    "cm = confusion_matrix(np.argmax(yTest,axis=1), pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T10:29:10.024652Z",
     "start_time": "2023-01-10T10:29:10.018785Z"
    }
   },
   "outputs": [],
   "source": [
    "# this will be usefull for the next sections\n",
    "def printMetrics(m):\n",
    "    score = m.evaluate(xTest,yTest)\n",
    "    print(\"%s: %.2f%%\" % (m.metrics_names[1], score[1]*100))\n",
    "\n",
    "    pred_test = np.argmax(m.predict(xTest),axis=1)\n",
    "\n",
    "    print(\"F1 score: \", f1_score(pred_test,np.argmax(yTest,axis=1),average=None))\n",
    "    print(\"F1 score micro: \", f1_score(pred_test,np.argmax(yTest,axis=1), average='micro'))\n",
    "    print(\"F1 score macro: \", f1_score(pred_test,np.argmax(yTest,axis=1), average='macro'))\n",
    "    cm = confusion_matrix(np.argmax(yTest,axis=1), pred_test)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data and clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first model will be learned using 20% of the data (all classes). Workers will load this first model and own another 20% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T10:29:16.140373Z",
     "start_time": "2023-01-10T10:29:16.030680Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = 0\n",
    "yTrain0 = []\n",
    "for cl in range(0,10):\n",
    "    cl0 = xTrain[y_train==cl]\n",
    "    n0 = len(cl0)\n",
    "    tmp += len(cl0[:n0//5])\n",
    "xTrain0 = np.empty(shape=(tmp,28,28), dtype=float)\n",
    "i = 0\n",
    "for cl in range(0,10):\n",
    "    cl0 = xTrain[y_train==cl]\n",
    "    n0 = len(cl0)//5\n",
    "    xTrain0[i:i+n0] = cl0[:n0]\n",
    "    i += n0\n",
    "    yTrain0 += [cl]*n0\n",
    "print(xTrain0.shape)\n",
    "print(len(yTrain0))\n",
    "yTrain0 = tensorflow.keras.utils.to_categorical(yTrain0, nbClasses)\n",
    "print(yTrain0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T10:29:20.533948Z",
     "start_time": "2023-01-10T10:29:20.511768Z"
    }
   },
   "outputs": [],
   "source": [
    "#this is **VERY** important for the splitting into validation and train in the fit method\n",
    "xTrain0, yTrain0 = shuffle(xTrain0, yTrain0, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Pre-learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T10:30:08.030815Z",
     "start_time": "2023-01-10T10:29:24.025010Z"
    }
   },
   "outputs": [],
   "source": [
    "# write the code for the server that will define and learn a neural network using xTrain0 and yTrain0\n",
    "model0 = #to be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T10:30:10.422063Z",
     "start_time": "2023-01-10T10:30:08.044579Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate this model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T10:30:11.243793Z",
     "start_time": "2023-01-10T10:30:10.435704Z"
    }
   },
   "outputs": [],
   "source": [
    "# we make a copy of this pre-learned model for restarts using different methods\n",
    "modelBase = copy.deepcopy(model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with 2 workers. They first receive a copy of the server. We assign the next 20% of xTrain and yTrain to the first worker and the next 20% to the second worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T10:30:12.730089Z",
     "start_time": "2023-01-10T10:30:11.256387Z"
    }
   },
   "outputs": [],
   "source": [
    "#Worker 1\n",
    "model1 = copy.deepcopy(model0)\n",
    "xTrain1 = np.empty(shape=(tmp,28,28), dtype=float)\n",
    "yTrain1 = []\n",
    "\n",
    "#Worker 2\n",
    "model2 = copy.deepcopy(model0)\n",
    "xTrain2 = np.empty(shape=(tmp,28,28), dtype=float)\n",
    "yTrain2 = []\n",
    "\n",
    "#data split: assign new 20% of train data to each worker \n",
    "i = 0\n",
    "for cl in range(0,10):\n",
    "    cl0 = xTrain[y_train==cl]\n",
    "    n0 = len(cl0)//5\n",
    "    xTrain1[i:i+n0] = cl0[n0:2*n0]\n",
    "    xTrain2[i:i+n0] = cl0[2*n0:3*n0]\n",
    "    i += n0\n",
    "    yTrain1 += [cl]*n0\n",
    "    yTrain2 += [cl]*n0\n",
    "yTrain1 = tensorflow.keras.utils.to_categorical(yTrain1, nbClasses)\n",
    "yTrain2 = tensorflow.keras.utils.to_categorical(yTrain2, nbClasses)\n",
    "\n",
    "xTrain1, yTrain1 = shuffle(xTrain1, yTrain1)\n",
    "xTrain2, yTrain2 = shuffle(xTrain2, yTrain2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 one epoch on each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T10:30:17.064965Z",
     "start_time": "2023-01-10T10:30:12.755363Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform one epoch for each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T13:41:43.611891Z",
     "start_time": "2023-01-06T13:41:40.921044Z"
    }
   },
   "outputs": [],
   "source": [
    "printMetrics(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 merging to the server using weight averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T13:52:32.029167Z",
     "start_time": "2023-01-06T13:52:32.022589Z"
    }
   },
   "outputs": [],
   "source": [
    "# first method: weight averaging\n",
    "## get the weights of all model, compute the average and use this result as weight for the server (model0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T13:52:59.848183Z",
     "start_time": "2023-01-06T13:52:57.669067Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T10:37:32.391338Z",
     "start_time": "2023-01-10T10:37:27.228377Z"
    }
   },
   "outputs": [],
   "source": [
    "# perform another epoch and print again the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add 2 other workers and do the fed learning again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 merging to the server using weights averaging on the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T15:43:27.179561Z",
     "start_time": "2023-01-06T15:43:27.171840Z"
    }
   },
   "outputs": [],
   "source": [
    "# second method: weights averaging on the last layer\n",
    "wlast0 = model0.get_layer('dense_42').get_weights() # 2 elements in the list\n",
    "nlast0 = len(wlast0)\n",
    "# similar processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 merging to the server using weights averaging on the last 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second method (bis): weights averaging only on dense layers (the last 2 layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Gradient averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Introduction to GradientTape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "[GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) allows to compute and record (tape) gradients of functions using automatic differentiation. An [introduction](https://medium.com/analytics-vidhya/tf-gradienttape-explained-for-keras-users-cc3f06276f22) is also worth to read. \n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T13:18:20.410458Z",
     "start_time": "2023-01-10T13:18:20.406228Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T13:20:30.088676Z",
     "start_time": "2023-01-10T13:20:30.081538Z"
    }
   },
   "outputs": [],
   "source": [
    "#lets initialize a variable:\n",
    "x = tf.Variable(4.0)\n",
    "\n",
    "# gradient tape is defined to record operations defining function y\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**3\n",
    "\n",
    "print(y) # value of y computed with x equal to 4.0\n",
    "print(tape.gradient(y,x)) # gradient of y with respect to variable x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that we can apply this to a neural network considered as a function, taking x as input, y as output and the w values as trainable variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-09T21:35:02.164288Z",
     "start_time": "2023-01-09T21:35:02.145103Z"
    }
   },
   "outputs": [],
   "source": [
    "with tensorflow.GradientTape() as tape:\n",
    "    # Make prediction\n",
    "    pred_y = model(xTrain)\n",
    "    # Calculate loss\n",
    "    model_loss = tensorflow.keras.losses.categorical_crossentropy(yTrain, pred_y)\n",
    "    \n",
    "# Calculate gradients\n",
    "model_gradients = tape.gradient(model_loss, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Using GradientTape on the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T13:28:48.330247Z",
     "start_time": "2023-01-10T13:28:45.983768Z"
    }
   },
   "outputs": [],
   "source": [
    "model0 = copy.deepcopy(modelBase)\n",
    "model1 = copy.deepcopy(model0)\n",
    "model2 = copy.deepcopy(model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T13:25:53.037646Z",
     "start_time": "2023-01-10T13:25:53.031770Z"
    }
   },
   "outputs": [],
   "source": [
    "# third method: gradient averaging\n",
    "# récuperer les gradients (GradientTape)\n",
    "#one iteration\n",
    "def step(m, data, labels):\n",
    "    with tensorflow.GradientTape() as tape:\n",
    "        # Make prediction\n",
    "        pred_y = m(data)\n",
    "        # Calculate loss\n",
    "        model_loss = tensorflow.keras.losses.categorical_crossentropy(labels, pred_y)\n",
    "    \n",
    "    # Calculate gradients\n",
    "    model_gradients = tape.gradient(model_loss, m.trainable_variables)\n",
    "    # Update model\n",
    "    m.optimizer.apply_gradients(zip(model_gradients, m.trainable_variables))\n",
    "    return model_gradients\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2.1 Only one iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T13:35:11.921547Z",
     "start_time": "2023-01-10T13:35:11.839238Z"
    }
   },
   "outputs": [],
   "source": [
    "# using bs as the batch size\n",
    "bs = 128\n",
    "# compute the first iteration \n",
    "n = 0 # first iteration\n",
    "# and memorize \n",
    "## grad1 the gradient for model1\n",
    "## grad2 the gradient for model2\n",
    "## compute the average \n",
    "## use this gradient for modifying weights of model0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T13:35:22.656971Z",
     "start_time": "2023-01-10T13:35:22.640850Z"
    }
   },
   "outputs": [],
   "source": [
    "# send gradients to the server and use the gradients to modify the weights in the server\n",
    "model0.optimizer.apply_gradients(zip(grad1,model0.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2.2 Only one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T13:36:57.434261Z",
     "start_time": "2023-01-10T13:36:49.297383Z"
    }
   },
   "outputs": [],
   "source": [
    "#the same for 1 epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-10T13:36:59.752474Z",
     "start_time": "2023-01-10T13:36:57.484863Z"
    }
   },
   "outputs": [],
   "source": [
    "printMetrics(model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2.3 Many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display evolution of metrics"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
